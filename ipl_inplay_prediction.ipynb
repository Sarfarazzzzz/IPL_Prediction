{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4a38ea95",
      "metadata": {
        "id": "4a38ea95"
      },
      "source": [
        "# üèè IPL In-Play Match Winner Prediction\n",
        "This notebook builds a machine learning model to predict the match winner after every ball using IPL data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e57c049",
      "metadata": {
        "id": "0e57c049",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d98bff2b-0474-4125-f507-525e5526c7ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.5)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.2)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%pip install xgboost lightgbm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "69af98a4",
      "metadata": {
        "id": "69af98a4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fddecf63",
      "metadata": {
        "id": "fddecf63"
      },
      "source": [
        "## Step 1: Load and Merge Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "40462ae3",
      "metadata": {
        "id": "40462ae3"
      },
      "outputs": [],
      "source": [
        "matches = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/IPL/matches.csv\")\n",
        "deliveries_raw = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/IPL/deliveries.csv\")\n",
        "\n",
        "# ---- Home Team Mapping ----\n",
        "home_venues = {\n",
        "    \"Chennai Super Kings\": [\"MA Chidambaram Stadium\"],\n",
        "    \"Mumbai Indians\": [\"Wankhede Stadium\"],\n",
        "    \"Kolkata Knight Riders\": [\"Eden Gardens\"],\n",
        "    \"Royal Challengers Bangalore\": [\"M Chinnaswamy Stadium\"],\n",
        "    \"Sunrisers Hyderabad\": [\"Rajiv Gandhi International Stadium, Uppal\"],\n",
        "    \"Delhi Capitals\": [\"Arun Jaitley Stadium\", \"Feroz Shah Kotla\"],\n",
        "    \"Punjab Kings\": [\"Punjab Cricket Association IS Bindra Stadium\"],\n",
        "    \"Rajasthan Royals\": [\"Sawai Mansingh Stadium\"],\n",
        "    \"Gujarat Titans\": [\"Narendra Modi Stadium\"],\n",
        "    \"Lucknow Super Giants\": [\"Bharat Ratna Shri Atal Bihari Vajpayee Ekana Cricket Stadium\"]\n",
        "}\n",
        "venue_to_home_team = {}\n",
        "for team, venues in home_venues.items():\n",
        "    for v in venues:\n",
        "        venue_to_home_team[v] = team\n",
        "matches[\"venue_home_team\"] = matches[\"venue\"].map(venue_to_home_team)\n",
        "\n",
        "# Use ONLY first innings to calculate match target\n",
        "first_innings = deliveries_raw[deliveries_raw[\"inning\"] == 1]\n",
        "targets = first_innings.groupby(\"match_id\")[\"total_runs\"].sum().reset_index()\n",
        "targets.columns = [\"match_id\", \"target\"]\n",
        "\n",
        "# Use 2nd innings for prediction\n",
        "second_innings = deliveries_raw[deliveries_raw[\"inning\"] == 2]\n",
        "\n",
        "# Merge everything\n",
        "df = second_innings.merge(matches[[\"id\", \"venue\", \"winner\", \"venue_home_team\"]],\n",
        "                          left_on=\"match_id\", right_on=\"id\", how=\"left\")\n",
        "df = df.merge(targets, on=\"match_id\", how=\"left\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nzRp7fz59Is",
        "outputId": "e71c3ba0-cc6e-4945-8c54-3135c135383e"
      },
      "id": "7nzRp7fz59Is",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f33be87d",
      "metadata": {
        "id": "f33be87d"
      },
      "source": [
        "## Step 2: Feature Engineering (Ball-by-Ball)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "4895f614",
      "metadata": {
        "id": "4895f614"
      },
      "outputs": [],
      "source": [
        "# ---- Feature Engineering ----\n",
        "df['total_runs_so_far'] = df.groupby('match_id')['total_runs'].cumsum()\n",
        "df['balls_so_far'] = df.groupby('match_id').cumcount() + 1\n",
        "df['balls_left'] = 120 - df['balls_so_far']\n",
        "df['current_run_rate'] = df['total_runs_so_far'] * 6 / df['balls_so_far']\n",
        "df['runs_left'] = df['target'] - df['total_runs_so_far']\n",
        "df['required_run_rate'] = df['runs_left'] * 6 / df['balls_left']\n",
        "df['wickets_so_far'] = df.groupby('match_id')['is_wicket'].cumsum()\n",
        "df['wickets_left'] = 10 - df['wickets_so_far']\n",
        "df['run_rate_diff'] = df['current_run_rate'] - df['required_run_rate']\n",
        "df['is_home_team'] = (df['batting_team'] == df['venue_home_team']).astype(int)\n",
        "\n",
        "# Clean\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df.dropna(subset=['required_run_rate'], inplace=True)\n",
        "\n",
        "# ---- Target ----\n",
        "df['batting_team_won'] = (df['batting_team'] == df['winner']).astype(int)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_match_phase(over):\n",
        "    if over <= 6:\n",
        "        return 'Powerplay'\n",
        "    elif over <= 15:\n",
        "        return 'Middle'\n",
        "    else:\n",
        "        return 'Death'\n",
        "df['match_phase'] = df['over'].apply(get_match_phase)\n",
        "\n",
        "# One-Hot Encode the 'match_phase' column\n",
        "phase_dummies = pd.get_dummies(df['match_phase'], prefix='phase', dtype=int)\n",
        "df = pd.concat([df, phase_dummies], axis=1)\n",
        "\n",
        "\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "# Now, fill any and all NaN values with 0. This PRESERVES your data.\n",
        "df.fillna(0, inplace=True)\n"
      ],
      "metadata": {
        "id": "hpADksmTPEz5"
      },
      "id": "hpADksmTPEz5",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Create the 'wicket_pressure' feature ---\n",
        "# This feature multiplies the required run rate by how many wickets have been lost.\n",
        "# (11 - wickets_left) gives us wickets lost (1 for the first wicket, 10 for the last).\n",
        "# We add 1 to the denominator to avoid dividing by zero if wickets_left is 0.\n",
        "df['wicket_pressure'] = (df['required_run_rate'] * (11 - df['wickets_left']))\n",
        "\n",
        "# Let's look at some examples to see how it behaves\n",
        "print(\"\\nWicket Pressure Feature Examples:\")\n",
        "print(df[['required_run_rate', 'wickets_left', 'wicket_pressure']].tail(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvhkdXSkPXbR",
        "outputId": "72d7c3cc-fa2d-45e9-a6dc-4d853071f897"
      },
      "id": "xvhkdXSkPXbR",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Wicket Pressure Feature Examples:\n",
            "        required_run_rate  wickets_left  wicket_pressure\n",
            "125736           0.315789             8         0.947368\n",
            "125737           0.214286             8         0.642857\n",
            "125738           0.109091             8         0.327273\n",
            "125739           0.000000             8         0.000000\n",
            "125740          -0.113208             8        -0.339623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the 'danger_index' feature\n",
        "# This feature is designed to be extremely sensitive to the number of wickets left.\n",
        "df['danger_index'] = df['required_run_rate'] / (df['wickets_left'] + 0.1)"
      ],
      "metadata": {
        "id": "bm4sJbbgbmJm"
      },
      "id": "bm4sJbbgbmJm",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4192823e",
      "metadata": {
        "id": "4192823e"
      },
      "source": [
        "## Step 3: Encode Categorical Variables"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAoFT7Abb6CF",
        "outputId": "8fd0990e-2f85-439f-ed03-afa3d0e43904"
      },
      "id": "bAoFT7Abb6CF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding complete using persistent encoders.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "34b1c083",
      "metadata": {
        "id": "34b1c083"
      },
      "outputs": [],
      "source": [
        "for col in ['batting_team', 'bowling_team', 'venue', 'venue_home_team']:\n",
        "    df[col] = LabelEncoder().fit_transform(df[col].astype(str))\n",
        "# Final feature list\n",
        "features_final = [\n",
        "    'batting_team', 'bowling_team', 'venue',\n",
        "    'balls_so_far', 'balls_left',\n",
        "    'total_runs_so_far', 'runs_left',\n",
        "    'current_run_rate', 'required_run_rate',\n",
        "    'wickets_left', 'run_rate_diff', 'is_home_team', 'phase_Middle',\n",
        "    'phase_Death', 'wicket_pressure', 'danger_index'\n",
        "]\n",
        "X = df[features_final]\n",
        "y = df['batting_team_won']\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f441744",
      "metadata": {
        "id": "9f441744"
      },
      "source": [
        "## Step 4: Train-Test Split and Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "05c60992",
      "metadata": {
        "id": "05c60992"
      },
      "outputs": [],
      "source": [
        "# New, better code\n",
        "X = df[features_final]\n",
        "y = df['batting_team_won']\n",
        "\n",
        "# Use the entire dataset for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "cf9d6eca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf9d6eca",
        "outputId": "083df140-9108-42d8-d862-551fe3d6c41b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Model: Random Forest\n",
            "Accuracy: 0.9732\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97     11996\n",
            "           1       0.97      0.98      0.97     13028\n",
            "\n",
            "    accuracy                           0.97     25024\n",
            "   macro avg       0.97      0.97      0.97     25024\n",
            "weighted avg       0.97      0.97      0.97     25024\n",
            "\n",
            "\n",
            "üîç Model: XGBoost\n",
            "Accuracy: 0.9734\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97     11996\n",
            "           1       0.97      0.97      0.97     13028\n",
            "\n",
            "    accuracy                           0.97     25024\n",
            "   macro avg       0.97      0.97      0.97     25024\n",
            "weighted avg       0.97      0.97      0.97     25024\n",
            "\n",
            "\n",
            "üîç Model: LightGBM\n",
            "[LightGBM] [Info] Number of positive: 52111, number of negative: 47985\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004730 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2131\n",
            "[LightGBM] [Info] Number of data points in the train set: 100096, number of used features: 16\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.520610 -> initscore=0.082488\n",
            "[LightGBM] [Info] Start training from score 0.082488\n",
            "Accuracy: 0.9090\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.90      0.90     11996\n",
            "           1       0.91      0.92      0.91     13028\n",
            "\n",
            "    accuracy                           0.91     25024\n",
            "   macro avg       0.91      0.91      0.91     25024\n",
            "weighted avg       0.91      0.91      0.91     25024\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.dropna(inplace=True)\n",
        "y = y[X.index]  # Align target with filtered features\n",
        "\n",
        "\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
        "    \"LightGBM\": LGBMClassifier()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nüîç Model: {name}\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(report)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hdVmnGdFHqV9"
      },
      "id": "hdVmnGdFHqV9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jwheFtx5HqTb"
      },
      "id": "jwheFtx5HqTb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assume LightGBM was best\n",
        "best_model = models[\"XGBoost\"]\n",
        "\n",
        "# Save the trained model\n",
        "with open(\"xgb_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(best_model, f)\n",
        "\n",
        "print(\"Best model saved as xgb_model.pkl\")"
      ],
      "metadata": {
        "id": "HC4cYTx3HqQf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5781ff76-474e-46fe-aa97-ac6f76e3acdd"
      },
      "id": "HC4cYTx3HqQf",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved as xgb_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ubzSyDT5HqNc"
      },
      "id": "ubzSyDT5HqNc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tYOyf12EHqJv"
      },
      "id": "tYOyf12EHqJv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XyILf8Y8HqGH"
      },
      "id": "XyILf8Y8HqGH",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
